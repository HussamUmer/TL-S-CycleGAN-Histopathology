{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYyMs2Gbjn3H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "import itertools\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear CUDA cache\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Ck8q88Mspaed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScRJ-64Ij-Yw"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5rM2akcj-Wa"
      },
      "outputs": [],
      "source": [
        "# Load Data\n",
        "#Sequence of transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224)),  # Resize images to 224x224 pixels\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "new_size = 1 #batch size\n",
        "dataset_A = datasets.ImageFolder(root='/content/drive/MyDrive/my_data/train/benign', transform=transform) #load benign dataset\n",
        "dataset_B = datasets.ImageFolder(root='/content/drive/MyDrive/my_data/train/malignant', transform=transform) #load malignant dataset\n",
        "#Data loader for each dataset\n",
        "loader_A = torch.utils.data.DataLoader(dataset_A, batch_size=new_size, shuffle=True)\n",
        "loader_B = torch.utils.data.DataLoader(dataset_B, batch_size=new_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDAqrnYBj-TA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def imshow(img):\n",
        "    img = img.numpy().transpose((1, 2, 0))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "dataiter_A = iter(loader_A)\n",
        "images_A, _ = next(dataiter_A)\n",
        "\n",
        "dataiter_B = iter(loader_B)\n",
        "images_B, _ = next(dataiter_B)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Sample from benign ()')\n",
        "imshow(images_A[0])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Sample from malignant ()')\n",
        "imshow(images_B[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWCl711aj-Q7"
      },
      "outputs": [],
      "source": [
        "#######Generator##########\n",
        "#########################\n",
        "\n",
        "class ResnetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, n_blocks=9, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
        "        assert(n_blocks >= 0)\n",
        "        super(ResnetGenerator, self).__init__()\n",
        "        self.input_nc = input_nc\n",
        "        self.output_nc = output_nc\n",
        "        self.ngf = ngf #no of generator filters\n",
        "        #n_blocks = resnet blocks\n",
        "\n",
        "        #Initial convlutional block\n",
        "        model = [nn.ReflectionPad2d(3),\n",
        "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=True),\n",
        "                 norm_layer(ngf),\n",
        "                 nn.ReLU(True)]\n",
        "\n",
        "        # Downsample\n",
        "        #reducing spatial dimensions\n",
        "        n_downsampling = 2 #no. of downsampling layers\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2**i\n",
        "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=True),\n",
        "                      norm_layer(ngf * mult * 2),\n",
        "                      nn.ReLU(True)]\n",
        "\n",
        "        # Resnet blocks\n",
        "        #using shortcut connections bypassing few layers\n",
        "        mult = 2**n_downsampling\n",
        "        for i in range(n_blocks):\n",
        "            model += [ResnetBlock(ngf * mult, padding_type='reflect', norm_layer=norm_layer, use_dropout=use_dropout, use_bias=True)]\n",
        "\n",
        "        # Upsample\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2**(n_downsampling - i)\n",
        "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
        "                                         kernel_size=3, stride=2,\n",
        "                                         padding=1, output_padding=1,\n",
        "                                         bias=True),\n",
        "                      norm_layer(int(ngf * mult / 2)),\n",
        "                      nn.ReLU(True)]\n",
        "\n",
        "        model += [nn.ReflectionPad2d(3)]\n",
        "        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
        "        model += [nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "#resnet block\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        # Create the convolutional block\n",
        "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
        "    #function to build convolution block\n",
        "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
        "        conv_block = [] #to hold layers\n",
        "        p = 0\n",
        "\n",
        "        #determining padding type for first layer\n",
        "        if padding_type == 'reflect':\n",
        "            conv_block += [nn.ReflectionPad2d(1)]\n",
        "        elif padding_type == 'replicate':\n",
        "            conv_block += [nn.ReplicationPad2d(1)]\n",
        "        else:\n",
        "            p = 1  # 'zero' padding\n",
        "        #first convolution layer\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
        "                       norm_layer(dim),\n",
        "                       nn.ReLU(True)]\n",
        "        #opyional dropout layer\n",
        "        if use_dropout:\n",
        "            conv_block += [nn.Dropout(0.5)]\n",
        "\n",
        "        #determining padding type for 2nd layer\n",
        "        p = 0\n",
        "        if padding_type == 'reflect':\n",
        "            conv_block += [nn.ReflectionPad2d(1)]\n",
        "        elif padding_type == 'replicate':\n",
        "            conv_block += [nn.ReplicationPad2d(1)]\n",
        "        else:\n",
        "            p = 1  # 'zero' padding\n",
        "        #second convolutional block\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
        "                       norm_layer(dim)]\n",
        "\n",
        "        return nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9lR6bb2j-NU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class CustomDiscriminator(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(CustomDiscriminator, self).__init__()\n",
        "        # Load the pre-trained VGG16 model\n",
        "        vgg16 = models.vgg16(pretrained=True)\n",
        "\n",
        "        # Remove the classifier part of VGG16\n",
        "        self.features = vgg16.features\n",
        "\n",
        "        # Calculate the size of the feature map after VGG16 features\n",
        "        # Assuming input image size of (3, 224, 224)\n",
        "        self.feature_map_size = 512 * 7 * 7\n",
        "\n",
        "        # Define the classifier for fake/real\n",
        "        self.fake_real_classifier = nn.Sequential(\n",
        "            nn.Linear(self.feature_map_size, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 1),  # Binary classification (fake/real)\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Define the classifier for benign/malignant\n",
        "        self.benign_malignant_classifier = nn.Sequential(\n",
        "            nn.Linear(self.feature_map_size, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes)  # Multi-class classification (benign/malignant)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features using VGG16\n",
        "        features = self.features(x)\n",
        "        features = features.view(features.size(0), -1)  # Flatten the feature map\n",
        "\n",
        "        # Fake/Real classification\n",
        "        fake_real_output = self.fake_real_classifier(features)\n",
        "\n",
        "        # Benign/Malignant classification\n",
        "        benign_malignant_output = self.benign_malignant_classifier(features)\n",
        "\n",
        "        return fake_real_output, benign_malignant_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRPBPMWRj-Lp"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7K-UKjhko7U"
      },
      "outputs": [],
      "source": [
        "input_nc = 3  # number of channels in the input images\n",
        "output_nc = 3  # number of channels in the output images\n",
        "n_residual_blocks = 9  # typical number for a CycleGAN\n",
        "\n",
        "lr = 0.0002\n",
        "beta1 = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QeQYcDxko49"
      },
      "outputs": [],
      "source": [
        "# Generators\n",
        "netG_A2B = ResnetGenerator(input_nc, output_nc, n_blocks=n_residual_blocks).to(device)\n",
        "netG_B2A = ResnetGenerator(input_nc, output_nc, n_blocks=n_residual_blocks).to(device)\n",
        "\n",
        "# Discriminators\n",
        "D_A = CustomDiscriminator().to(device)\n",
        "D_B = CustomDiscriminator().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XCPjHALko1d"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "# Optimizers\n",
        "# Define optimizers\n",
        "optimizer_G = optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_D_A = optim.Adam(D_A.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_D_B = optim.Adam(D_B.parameters(), lr=lr, betas=(beta1, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ducpFdhbkozb"
      },
      "outputs": [],
      "source": [
        "# Define loss functions\n",
        "criterion_GAN = nn.MSELoss().to(device)\n",
        "criterion_cycle = nn.L1Loss().to(device)\n",
        "criterion_identity = nn.L1Loss().to(device)\n",
        "criterion_classification = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a7k_66mkouR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "def plot_single_real_and_fake_image(real_image, fake_image):\n",
        "    \"\"\"\n",
        "    Plots a comparison of a single real and a single generated (fake) image.\n",
        "\n",
        "    Parameters:\n",
        "    - real_image: a single Tensor image (C, H, W).\n",
        "    - fake_image: a single Tensor image (C, H, W).\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 4))\n",
        "\n",
        "    # Display the real image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Real Image\")\n",
        "    real_image = vutils.make_grid(real_image, normalize=True).permute(1, 2, 0).cpu().numpy()\n",
        "    plt.imshow(real_image)\n",
        "\n",
        "    # Display the fake image\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Generated Image\")\n",
        "    fake_image = vutils.make_grid(fake_image, normalize=True).permute(1, 2, 0).cpu().numpy()\n",
        "    plt.imshow(fake_image)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKYb3fgBkoqx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "def save_models_to_drive(epoch, netG_A2B, netG_B2A, D_A, D_B, drive_path='/content/drive/MyDrive/vgg_16_CycleGAN_Models'):\n",
        "    \"\"\"\n",
        "    Save model parameters to Google Drive.\n",
        "\n",
        "    Parameters:\n",
        "        epoch (int): The current epoch number.\n",
        "        netG_A2B (nn.Module): Generator model from domain A to B.\n",
        "        netG_B2A (nn.Module): Generator model from domain B to A.\n",
        "        netD_A (nn.Module): Discriminator model for domain A.\n",
        "        netD_B (nn.Module): Discriminator model for domain B.\n",
        "        drive_path (str): The path in Google Drive to save the models.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(drive_path):\n",
        "        os.makedirs(drive_path)\n",
        "\n",
        "    # Define file paths for saving\n",
        "    path_G_A2B = os.path.join(drive_path, f'netG_A2B_epoch_{epoch}.pth')\n",
        "    path_G_B2A = os.path.join(drive_path, f'netG_B2A_epoch_{epoch}.pth')\n",
        "    path_D_A = os.path.join(drive_path, f'netD_A_epoch_{epoch}.pth')\n",
        "    path_D_B = os.path.join(drive_path, f'netD_B_epoch_{epoch}.pth')\n",
        "\n",
        "    # Save the models\n",
        "    torch.save(netG_A2B.state_dict(), path_G_A2B)\n",
        "    torch.save(netG_B2A.state_dict(), path_G_B2A)\n",
        "    torch.save(D_A.state_dict(), path_D_A)\n",
        "    torch.save(D_B.state_dict(), path_D_B)\n",
        "\n",
        "    print(f\"Saved models at epoch {epoch} to {drive_path}\")\n",
        "\n",
        "# Example usage within the training loop:\n",
        "# save_models_to_drive(epoch, netG_A2B, netG_B2A, netD_A, netD_B)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear CUDA cache\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "QL5AtDnvpq2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 25\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "import itertools\n",
        "import time\n",
        "\n",
        "import os\n",
        "\n",
        "# Record the total training start time\n",
        "total_training_start_time = time.time()\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Record the start time of the epoch\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    for i, (real_A, real_B) in enumerate(zip(loader_A, loader_B)):\n",
        "        # Set model input\n",
        "        real_A = Variable(real_A[0].to(device)) # moving images from domain A to CUDA\n",
        "        real_B = Variable(real_B[0].to(device)) # moving images from domain B to CUDA\n",
        "\n",
        "        # -------------------------------\n",
        "        #  Train Generators A2B and B2A\n",
        "        # -------------------------------\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Identity loss\n",
        "        loss_id_A = criterion_identity(netG_B2A(real_A), real_A)\n",
        "        loss_id_B = criterion_identity(netG_A2B(real_B), real_B)\n",
        "\n",
        "        # GAN loss\n",
        "        fake_B = netG_A2B(real_A) # generating images from A to B domain\n",
        "        pred_fake, class_fake_B = D_B(fake_B)  # predicting real/fake and class\n",
        "        loss_GAN_A2B = criterion_GAN(pred_fake, torch.ones(pred_fake.size(), device=device))\n",
        "\n",
        "        fake_A = netG_B2A(real_B) # generating images from B to A domain\n",
        "        pred_fake, class_fake_A = D_A(fake_A)  # predicting real/fake and class\n",
        "        loss_GAN_B2A = criterion_GAN(pred_fake, torch.ones(pred_fake.size(), device=device))\n",
        "\n",
        "        # Cycle loss\n",
        "        recovered_A = netG_B2A(fake_B)\n",
        "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A)\n",
        "\n",
        "        recovered_B = netG_A2B(fake_A)\n",
        "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B)\n",
        "\n",
        "        # Classification loss for fake images (benign/malignant)\n",
        "        target_fake_B = torch.full((class_fake_B.size(0),), 1, device=device, dtype=torch.long)  # All fake_B are malignant (label 1)\n",
        "        target_fake_A = torch.full((class_fake_A.size(0),), 0, device=device, dtype=torch.long)  # All fake_A are benign (label 0)\n",
        "        loss_class_fake_B = criterion_classification(class_fake_B, target_fake_B)\n",
        "        loss_class_fake_A = criterion_classification(class_fake_A, target_fake_A)\n",
        "\n",
        "        # Total loss for Generators\n",
        "        loss_G = (loss_id_A + loss_id_B + loss_GAN_A2B + loss_GAN_B2A +\n",
        "                  loss_cycle_ABA + loss_cycle_BAB + loss_class_fake_B + loss_class_fake_A)\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # -----------------------\n",
        "        #  Train Discriminator D_A\n",
        "        # -----------------------\n",
        "        optimizer_D_A.zero_grad()\n",
        "\n",
        "        # Real loss\n",
        "        pred_real_A, class_real_A = D_A(real_A)\n",
        "        loss_D_real_A = criterion_GAN(pred_real_A, torch.ones(pred_real_A.size(), device=device))\n",
        "        target_real_A = torch.full((class_real_A.size(0),), 0, device=device, dtype=torch.long)  # All real_A are benign (label 0)\n",
        "        loss_class_real_A = criterion_classification(class_real_A, target_real_A)\n",
        "\n",
        "        # Fake loss (detach to avoid training G on these labels)\n",
        "        pred_fake_A, class_fake_A = D_A(fake_A.detach())\n",
        "        loss_D_fake_A = criterion_GAN(pred_fake_A, torch.zeros(pred_fake_A.size(), device=device))\n",
        "        loss_class_fake_A = criterion_classification(class_fake_A, target_fake_A)\n",
        "\n",
        "        # Total loss for Discriminator A\n",
        "        loss_D_A = (loss_D_real_A + loss_D_fake_A + loss_class_real_A + loss_class_fake_A) / 2\n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "        # -----------------------\n",
        "        #  Train Discriminator D_B\n",
        "        # -----------------------\n",
        "        optimizer_D_B.zero_grad()\n",
        "\n",
        "        # Real loss\n",
        "        pred_real_B, class_real_B = D_B(real_B)\n",
        "        loss_D_real_B = criterion_GAN(pred_real_B, torch.ones(pred_real_B.size(), device=device))\n",
        "        target_real_B = torch.full((class_real_B.size(0),), 1, device=device, dtype=torch.long)  # All real_B are malignant (label 1)\n",
        "        loss_class_real_B = criterion_classification(class_real_B, target_real_B)\n",
        "\n",
        "        # Fake loss (detach to avoid training G on these labels)\n",
        "        pred_fake_B, class_fake_B = D_B(fake_B.detach())\n",
        "        loss_D_fake_B = criterion_GAN(pred_fake_B, torch.zeros(pred_fake_B.size(), device=device))\n",
        "        loss_class_fake_B = criterion_classification(class_fake_B, target_fake_B)\n",
        "\n",
        "        # Total loss for Discriminator B\n",
        "        loss_D_B = (loss_D_real_B + loss_D_fake_B + loss_class_real_B + loss_class_fake_B) / 2\n",
        "        loss_D_B.backward()\n",
        "        optimizer_D_B.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Log Progress\n",
        "        # ---------------------\n",
        "        print(f\"Epoch [{epoch}/{num_epochs}] Batch {i}/{len(loader_A)} \\\n",
        "              Loss D_A: {loss_D_A.item()}, Loss D_B: {loss_D_B.item()} \\\n",
        "              Loss G: {loss_G.item()}\")\n",
        "\n",
        "        # If at save interval => save generated image samples\n",
        "        if i % 20 == 0:  # For example, visualize every 20 batches\n",
        "            plot_single_real_and_fake_image(real_A[0], fake_B[0])  # Pass the first image of the batch\n",
        "            plot_single_real_and_fake_image(real_B[0], fake_A[0])\n",
        "\n",
        "            # Predict class of images and print\n",
        "            _, class_real_A = D_A(real_A)\n",
        "            _, class_real_B = D_B(real_B)\n",
        "            _, class_fake_A = D_A(fake_A)\n",
        "            _, class_fake_B = D_B(fake_B)\n",
        "\n",
        "            pred_class_real_A = class_real_A.argmax(dim=1).item()\n",
        "            pred_class_real_B = class_real_B.argmax(dim=1).item()\n",
        "            pred_class_fake_A = class_fake_A.argmax(dim=1).item()\n",
        "            pred_class_fake_B = class_fake_B.argmax(dim=1).item()\n",
        "\n",
        "            print(f\"Predicted class for real_A: {'Benign' if pred_class_real_A == 0 else 'Malignant'}\")\n",
        "            print(f\"Predicted class for real_B: {'Benign' if pred_class_real_B == 0 else 'Malignant'}\")\n",
        "            print(f\"Predicted class for fake_A: {'Benign' if pred_class_fake_A == 0 else 'Malignant'}\")\n",
        "            print(f\"Predicted class for fake_B: {'Benign' if pred_class_fake_B == 0 else 'Malignant'}\")\n",
        "\n",
        "    # Record the end time of the epoch\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_duration = epoch_end_time - epoch_start_time\n",
        "    print(f\"Epoch {epoch} completed in {epoch_duration:.2f} seconds\")\n",
        "\n",
        "    # Update learning rates\n",
        "    #lr_scheduler_G.step()\n",
        "    #lr_scheduler_D_A.step()\n",
        "    #lr_scheduler_D_B.step()\n",
        "\n",
        "    if (epoch + 1) % 1 == 0:  # Every 10 epochs\n",
        "       save_models_to_drive(epoch, netG_A2B, netG_B2A, D_A, D_B)\n",
        "\n",
        "# After the final epoch, save the refined generated images\n",
        "#save_final_generated_images(G, dataloader, classifier, epoch=num_epochs, base_directory=\"output_breakhis/final_images\", device=device)\n",
        "\n",
        "# Record the total training end time\n",
        "total_training_end_time = time.time()\n",
        "total_training_duration = total_training_end_time - total_training_start_time\n",
        "print(f\"Total training time: {total_training_duration:.2f} seconds\")"
      ],
      "metadata": {
        "id": "7pxg7TKhcpri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KPdNc2d3iW29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eJ72yc5yusXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XYf3PsbviWvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKKeB1o5mDxv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}